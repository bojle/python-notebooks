{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac63dea-1689-43d3-acc6-93ce22159c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 16:50:59.585841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9856f7-e4b4-427d-b9c8-f3cdd13ec403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 16:51:04.480443: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-08-25 16:51:04.480468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: machine\n",
      "2023-08-25 16:51:04.480474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: machine\n",
      "2023-08-25 16:51:04.480582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.104.5\n",
      "2023-08-25 16:51:04.480603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.104.5\n",
      "2023-08-25 16:51:04.480609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.104.5\n",
      "2023-08-25 16:51:04.483256: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74da53cf-49c1-4d91-81e4-564fd93860d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = load_img(image, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9423f85-7823-4068-9ac6-a0ebed241aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1917036-1640-418d-a86c-d231575ccff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569f6df4-5a6e-4616-873e-cd7b4e610b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39aa66d3-f8a4-4e1d-9ee4-7b38797f6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "for i in range(500):\n",
    "    img = preprocess(f'tiny-imagenet-200/val/images/val_{i}.JPEG')\n",
    "    train_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0368a66f-340f-4ee4-95a9-80b9ac026c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    data = tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100)\n",
    "    for input_value in data:\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d2a6c9-e2f7-4c97-9308-4a147f2f88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.representative_dataset = representative_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb710d-b989-4f5c-8906-3a106f7ccfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6zeldof8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6zeldof8/assets\n"
     ]
    }
   ],
   "source": [
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bb55864-fc40-4fbd-894b-31b95f150e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00ca4282-8b76-4174-be83-a659d5ad8850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n",
      "mosquito_net (11.33%)\n",
      "toilet_tissue (2.70%)\n",
      "shower_curtain (2.00%)\n"
     ]
    }
   ],
   "source": [
    "image = preprocess('images/mug.jpg')\n",
    "label = decode_predictions(model.predict(image))\n",
    "for i in range(3):\n",
    "    print('%s (%.2f%%)' % (label[0][i][1], label[0][i][2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fb1a5-0f9c-446e-8877-a76e104efd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37528cc1-305b-48de-8ca3-593fd9bafbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = [array([[[[ 4.29470569e-01,  1.17273867e-01,  3.40129584e-02, ...,\n",
    "           -1.32241577e-01, -5.33475243e-02,  7.57738389e-03],\n",
    "          [ 5.50379455e-01,  2.08774377e-02,  9.88311544e-02, ...,\n",
    "           -8.48205537e-02, -5.11389151e-02,  3.74943428e-02],\n",
    "          [ 4.80015397e-01, -1.72696680e-01,  3.75577137e-02, ...,\n",
    "           -1.27135560e-01, -5.02991639e-02,  3.48965675e-02]],\n",
    " \n",
    "         [[ 3.73466998e-01,  1.62062630e-01,  1.70863140e-03, ...,\n",
    "           -1.48207128e-01, -2.35300660e-01, -6.30356818e-02],\n",
    "          [ 4.40074533e-01,  4.73412387e-02,  5.13819456e-02, ...,\n",
    "           -9.88498852e-02, -2.96195745e-01, -7.04357103e-02],\n",
    "          [ 4.08547401e-01, -1.70375049e-01, -4.96297423e-03, ...,\n",
    "           -1.22360572e-01, -2.76450396e-01, -3.90796512e-02]],\n",
    " \n",
    "         [[-6.13601133e-02,  1.35693997e-01, -1.15694344e-01, ...,\n",
    "           -1.40158370e-01, -3.77666801e-01, -3.00509870e-01],\n",
    "          [-8.13870355e-02,  4.18543853e-02, -1.01763301e-01, ...,\n",
    "           -9.43124294e-02, -5.05662560e-01, -3.83694321e-01],\n",
    "          [-6.51455522e-02, -1.54351532e-01, -1.38038069e-01, ...,\n",
    "           -1.29404560e-01, -4.62243795e-01, -3.23985279e-01]]],\n",
    "\n",
    "clipped = array([[[[ 4.29470569e-01,  1.17273867e-01,  3.40129584e-02, ...,\n",
    "           -1.32241577e-01, -5.33475243e-02,  7.57738389e-03],\n",
    "          [ 5.50379455e-01,  2.08774377e-02,  9.88311544e-02, ...,\n",
    "           -8.48205537e-02, -5.11389151e-02,  3.74943428e-02],\n",
    "          [ 4.80015397e-01, -1.72696680e-01,  3.75577137e-02, ...,\n",
    "           -1.27135560e-01, -5.02991639e-02,  3.48965675e-02]],\n",
    " \n",
    "         [[ 3.73466998e-01,  1.62062630e-01,  1.70863140e-03, ...,\n",
    "           -1.48207128e-01, -2.35300660e-01, -6.30356818e-02],\n",
    "          [ 4.40074533e-01,  4.73412387e-02,  5.13819456e-02, ...,\n",
    "           -9.88498852e-02, -2.96195745e-01, -7.04357103e-02],\n",
    "          [ 4.08547401e-01, -1.70375049e-01, -4.96297423e-03, ...,\n",
    "           -1.22360572e-01, -2.76450396e-01, -3.90796512e-02]],\n",
    " \n",
    "         [[-6.13601133e-02,  1.35693997e-01, -1.15694344e-01, ...,\n",
    "           -1.40158370e-01, -3.77666801e-01, -3.00509870e-01],\n",
    "          [-8.13870355e-02,  4.18543853e-02, -1.01763301e-01, ...,\n",
    "           -9.43124294e-02, -5.05662560e-01, -3.83694321e-01],\n",
    "          [-6.51455522e-02, -1.54351532e-01, -1.38038069e-01, ...,\n",
    "           -1.29404560e-01, -4.62243795e-01, -3.23985279e-01]]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c84d2-ade6-4644-a024-4e9689fcdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_disk():\n",
    "    smodel = tf.keras.applications.vgg16.VGG16()\n",
    "    smodel.save(\"vgg16-pretrained.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
